{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d721aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TrafficVolumeAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4cebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset into a PySpark DataFrame\n",
    "file_path = \"file:///home/hduser/Desktop/SEM2_CA1/da_sem2_ca1_rep/dataset.csv\"\n",
    "df = spark.read.csv(file_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e37713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ff236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying first few rows\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc58d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns \n",
    "columns_to_drop = ['STATISTICS', 'TLIST(A1)', 'C02875V03459', 'UNIT']\n",
    "df = df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying first few rows\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd522fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering thr rows as required\n",
    "df = df.filter(df['Statistic Label'] == \"Traffic Volume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_counts = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "missing_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6ada45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting values for plotting\n",
    "years = df.select(\"Year\").rdd.flatMap(lambda x: x).collect()\n",
    "traffic_volumes = df.select(\"VALUE\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af5fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting traffic volume over the years with logarithmic scale on Y-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(years, traffic_volumes, marker='o', linestyle='-')\n",
    "plt.yscale('log')  # Set logarithmic scale for Y-axis\n",
    "plt.title(\"Traffic Volume Over the Years\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Traffic Volume\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80695d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
